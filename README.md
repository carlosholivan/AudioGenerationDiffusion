# <span style="color:#9EB1FF; font-size:30.0pt">AUDIO GENERATION WITH DIFFUSION MODELS</span>


This repository is maintained by [**Carlos Hernández-Oliván**](https://carlosholivan.github.io/index.html)(carloshero@unizar.es) and it presents the State of the Art of Audio Generation with Diffusion models.

Make a pull request if you want to contribute to this references list.

All the images belong to their corresponding authors.

## Table of Contents
## <span id="index"></span>

1. [Papers](#papers)
    - [2022](#2022)
    - [2021](#2021)

2. [Diffusion theory papers](#theory)

3. [Resources](#resources)



## <span id="papers" style="color:#9EB1FF; font-size:25.0pt">1. Papers</span>

### <span id="2022" style="color:#A8FF9E; font-size:20.0pt">2022</span>

#### <span id="mm-diffusion" style="color:#FF9EC3; font-size:15.0pt">MM-Diffusion</span>

<img src="images/mm-diffusion.jpg" alt="isolated" width="400"/>

Ruan, Ludan and Ma, Yiyang and Yang, Huan and He, Huiguo and Liu, Bei and Fu, Jianlong and Yuan, Nicholas Jing and Jin, Qin and Guo, Baining. (2022). MM-Diffusion: Learning Multi-Modal Diffusion Models for Joint Audio and Video Generation.

[Paper](https://arxiv.org/pdf/2212.09478v1.pdf) [GitHub](https://github.com/researchmm/MM-Diffusion)


### <span id="2021" style="color:#A8FF9E; font-size:20.0pt">2021</span>

#### <span id="diffwave" style="color:#FF9EC3; font-size:15.0pt">Diffwave (ICLR 2021)</span>

<img src="images/diffwave.png" alt="isolated" width="200"/>

Kong, Z., Ping, W., Huang, J., Zhao, K., & Catanzaro, B. (2020). Diffwave: A versatile diffusion model for audio synthesis. ICLR 2021.

[Paper](https://arxiv.org/pdf/2009.09761.pdf)


## <span id="theory" style="color:#9EB1FF; font-size:25.0pt">2. Theory</span>


## <span id="resources" style="color:#9EB1FF; font-size:25.0pt">3. Resources</span>

- [Lil's blog diffusion](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)


[&uarr; Table of Contents](#index)
